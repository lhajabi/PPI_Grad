{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lhajabi/PPI_Grad/blob/main/LSTM_PPI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0M3JgllR5Ses"
      },
      "outputs": [],
      "source": [
        "!pip3 install keras-visualizer\n",
        "from keras_visualizer import visualizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_gX6z2sjn5X"
      },
      "source": [
        "# imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlFkkRHgjn5h"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"Keras version: {tf.keras.__version__ if hasattr(tf.keras, '__version__') else tf.keras.__path__[0].split('/')[-1]}\")\n",
        "print(f\"Standalone Keras version: {keras.__version__}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9G7RuHfjn5h"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from itertools import product\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import os\n",
        "import json\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKsvLf0hjn5h"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from keras.layers import LSTM, GRU, Input, concatenate, Flatten, BatchNormalization, Dense, Dropout, Embedding, Reshape, RNN, SimpleRNN,Bidirectional\n",
        "from keras.models import Model,Sequential\n",
        "from keras.callbacks import Callback,EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score,roc_curve,auc,matthews_corrcoef,accuracy_score\n",
        "from keras.metrics import Precision, Recall,Accuracy\n",
        "from keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZ3-ZINmAL-5"
      },
      "source": [
        "#Data upload:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4Y3Zrp6AL-6"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIRT2nwIAL-6"
      },
      "outputs": [],
      "source": [
        "df_links = pd.read_csv('/content/drive/MyDrive/Data/GENERATED DATASETS/Generated200k_(POS40-0.7)_50:50.txt', delimiter=',')\n",
        "df_links.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VyEmfkyBSdy"
      },
      "source": [
        "#Data Preperation:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBFTWEma1mW6"
      },
      "source": [
        "tokenization and padding:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_1_nMflAL-7"
      },
      "outputs": [],
      "source": [
        "def generate_word_token_dict(amino_acids_list, k):\n",
        "    words = set(product(amino_acids_list, repeat=k))\n",
        "    words = [''.join(word) for word in words]\n",
        "    tokens = [int(i) for i in range(1, len(words) + 1)]\n",
        "    #num_digits = len(str(max(tokens)))\n",
        "    #tokens = [f\"{token:0{num_digits}}\" for token in tokens]\n",
        "    word_token = dict(zip(words, tokens))\n",
        "    return word_token\n",
        "\n",
        "def tokenization(cell, word_token, n_grams):\n",
        "  if len(cell)/n_grams != 0:\n",
        "    cell_0 = cell[len(cell)%n_grams:]\n",
        "  cell_1 = [cell_0[i:i+n_grams] for i in range(0, len(cell_0), n_grams)]\n",
        "  #print(cell_1)\n",
        "  cell_1 = [word_token[word] for word in cell_1]\n",
        "  #cell = ''.join(cell_1)\n",
        "  cell = cell_1\n",
        "  return cell\n",
        "\n",
        "def pad(cell, fixed_length):\n",
        "    if len(cell) > fixed_length:\n",
        "        # If the original list is longer, remove leftmost elements\n",
        "        return cell[-fixed_length:]\n",
        "    elif len(cell) < fixed_length:\n",
        "        # If the original list is shorter, pad leftmost with zeroes\n",
        "        return [0] * (fixed_length - len(cell)) + cell\n",
        "    else:\n",
        "        # If the original list has the desired length, no modifications are needed\n",
        "        return cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpZAGAUEWt7x"
      },
      "outputs": [],
      "source": [
        "amino_acids_list = ['A','B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y','Z']\n",
        "n_grams = 3\n",
        "fixed_length = 1000\n",
        "word_token = generate_word_token_dict(amino_acids_list, k=n_grams)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0id7lVH0RDQl"
      },
      "outputs": [],
      "source": [
        "columns = ['protein1', 'protein2']\n",
        "for column in columns:\n",
        "  df_links[column] = df_links[column].apply(func = tokenization, args = (word_token, n_grams,))\n",
        "  df_links[column] = df_links[column].apply(func= pad, args = (fixed_length,))\n",
        "df_links.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQ30ic_CAL-7"
      },
      "source": [
        "#Split Data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwEWgalvAL-7"
      },
      "outputs": [],
      "source": [
        "x_data = df_links[['protein1', 'protein2']]\n",
        "y_data = df_links['combined_score']\n",
        "x_train, x_temp, y_train, y_temp = train_test_split(x_data, y_data, test_size=0.3, random_state=42, shuffle=True, stratify=None)\n",
        "x_validate, x_test, y_validate, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=43, shuffle=True, stratify=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AITsaCcAL-7"
      },
      "outputs": [],
      "source": [
        "print(x_train.info())\n",
        "print(x_validate.info())\n",
        "print(x_test.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyWwxBiHAL-8"
      },
      "outputs": [],
      "source": [
        "input_1_train = np.array(x_train['protein1'].values.tolist())\n",
        "input_2_train = np.array(x_train['protein2'].values.tolist())\n",
        "output_train = np.array(y_train)\n",
        "\n",
        "input_1_validate = np.array(x_validate['protein1'].values.tolist())\n",
        "input_2_validate = np.array(x_validate['protein2'].values.tolist())\n",
        "output_validate = np.array(y_validate)\n",
        "\n",
        "input_1_test = np.array(x_test['protein1'].values.tolist())\n",
        "input_2_test = np.array(x_test['protein2'].values.tolist())\n",
        "output_test = np.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PoGI76pYAL-8"
      },
      "outputs": [],
      "source": [
        "x_train = [input_1_train, input_2_train]\n",
        "y_train = output_train\n",
        "\n",
        "x_val = [input_1_validate, input_2_validate]\n",
        "y_val = output_validate\n",
        "\n",
        "x_test = [input_1_test, input_2_test]\n",
        "y_test = output_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9uOuuygAL-9"
      },
      "source": [
        "# Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4UKgTLb9fKI"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6EoSSPRAL-8"
      },
      "source": [
        "#Metrics and Callbacks:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0z8WlzVhKW-3"
      },
      "outputs": [],
      "source": [
        "thresholds = [0.3, 0.5, 0.7, 0.9]\n",
        "metrics = [ #Available metrics for binary_crossentropy are: loss,precision,recall,auc,auc_1,val_loss,val_precision,val_recall,val_auc,val_auc_1\n",
        "    keras.metrics.BinaryAccuracy(threshold=0.5),\n",
        "    #keras.metrics.Precision(thresholds = thresholds),\n",
        "    #keras.metrics.Recall(thresholds = thresholds),\n",
        "    #keras.metrics.AUC(curve = 'ROC', name = 'ROC'),\n",
        "    #keras.metrics.AUC(curve=\"PR\", name = 'PR'),\n",
        "    #f1_score,\n",
        "    keras.metrics.BinaryCrossentropy()\n",
        "    ]\n",
        "loss_function = 'binary_crossentropy'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPBRZiNlKJz0"
      },
      "outputs": [],
      "source": [
        "import keras.backend as K\n",
        "\"\"\"def f1_score(y_true, y_pred):\n",
        "    precision = Precision()(y_true, y_pred)\n",
        "    recall = Recall()(y_true, y_pred)\n",
        "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
        "\"\"\"\n",
        "def calculate_metrics(y_true, y_pred, threshold):\n",
        "    y_pred_binary = (y_pred > threshold).astype(int)\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred_binary).ravel()\n",
        "\n",
        "    sensitivity = tp / (tp + fn)\n",
        "    specificity = tn / (tn + fp)\n",
        "    mcc = matthews_corrcoef(y_true, y_pred_binary)\n",
        "    accuracy = accuracy_score(y_true, y_pred_binary)\n",
        "    precision = precision_score(y_true, y_pred_binary)\n",
        "    recall = recall_score(y_true, y_pred_binary)\n",
        "    f1 = f1_score(y_true, y_pred_binary)\n",
        "    auc = roc_auc_score(y_true, y_pred)\n",
        "\n",
        "    return sensitivity, specificity, mcc, accuracy, precision, recall, f1, auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9slFRjZ7ssc"
      },
      "outputs": [],
      "source": [
        "def find_best_threshold(model, x_val, y_val):\n",
        "    y_pred = model.predict(x_val)\n",
        "\n",
        "    # Generate a range of thresholds\n",
        "    thresholds = np.arange(0, 1.01, 0.01)\n",
        "    best_threshold = None\n",
        "    best_mcc = -1\n",
        "\n",
        "    # Iterate through thresholds and find the best one\n",
        "    for threshold in thresholds:\n",
        "        sens,spec,mcc,acc,prec, rec, f1,auc = calculate_metrics(y_val, y_pred, threshold)\n",
        "        if mcc > best_mcc:\n",
        "            best_mcc = mcc\n",
        "            best_threshold = threshold\n",
        "\n",
        "    return best_threshold,best_mcc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJYlZ5UzAL-8"
      },
      "outputs": [],
      "source": [
        "class ConfusionMatrixCallback(keras.callbacks.Callback):\n",
        "  def __init__(self, x_val, y_val):\n",
        "        super(ConfusionMatrixCallback, self).__init__()\n",
        "        self.x_val, self.y_val = x_val, y_val\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "        predictions = self.model.predict(x = x_val)\n",
        "        # Convert probabilities to classes using the threshold\n",
        "        predictions = (predictions >= 0.5).astype(int)\n",
        "        cm = confusion_matrix(y_val, predictions)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=True, yticklabels=True)\n",
        "        plt.title('Confusion Matrix - Epoch {}'.format(epoch))\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('True')\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjKYVfl_jbqK"
      },
      "outputs": [],
      "source": [
        "def rate_model(y_true, y_pred, cm_threshold = 0.5):\n",
        "  for m in metrics:\n",
        "    m.update_state(y_true, y_pred)\n",
        "    print('{} : {}'.format(m.name, m.result()))\n",
        "  y_pred = (y_pred >= cm_threshold).astype(int)\n",
        "  cm = confusion_matrix(y_true, y_pred)\n",
        "  plt.figure(figsize=(8, 6))\n",
        "  sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=True, yticklabels=True)\n",
        "  plt.title('Confusion Matrix')\n",
        "  plt.xlabel('Predicted')\n",
        "  plt.ylabel('True')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWoPnYKJs1Bz"
      },
      "outputs": [],
      "source": [
        "log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwWN6e9jjuie"
      },
      "outputs": [],
      "source": [
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor= 'val_loss' , factor=0.2, patience=0.1, min_lr=0.001, verbose=1)\n",
        "confusion_matrix_callback = ConfusionMatrixCallback(x_val, y_val)\n",
        "early_stopping = EarlyStopping(monitor= 'val_loss', patience=5, restore_best_weights = True)\n",
        "callbacks = [early_stopping, reduce_lr, tensorboard_callback]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1O6kARfaQlE"
      },
      "source": [
        "#LSTM:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kTWm2nRRTx5"
      },
      "outputs": [],
      "source": [
        "#inputs\n",
        "protein_1 = tf.keras.layers.Input(shape=(fixed_length,), name='protein1')\n",
        "protein_2 = tf.keras.layers.Input(shape=(fixed_length,), name='protein2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VG1kvmpkSCG7"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.callbacks import Callback,EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding,BatchNormalization,LSTM, Dense,Dropout,concatenate\n",
        "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
        "\n",
        "embedding = tf.keras.layers.Embedding(input_dim = len(word_token) + 1, output_dim = 512, mask_zero = 1,  input_length=fixed_length)\n",
        "embedding_1 = embedding(protein_1)\n",
        "embedding_2 = embedding(protein_2)\n",
        "model_0 = Model(inputs = [protein_1, protein_2], outputs = [embedding_1,embedding_2])\n",
        "\n",
        "model_1 = Sequential()\n",
        "model_1.add(BatchNormalization(input_shape = (fixed_length,512)))\n",
        "model_1.add(LSTM(name = 'LSTM_Layer',units = 64, activation='tanh', recurrent_activation='sigmoid'))\n",
        "model_1.add(Dense( 64, activation='elu'))\n",
        "model_1.add(BatchNormalization())\n",
        "model_1.add(Dropout(0.6))\n",
        "\n",
        "feature_array_128 = concatenate([model_1(model_0.outputs[0]), model_1(model_0.outputs[1])])\n",
        "x = Dense(512, activation='elu')(feature_array_128)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(1, activation='sigmoid')(x)\n",
        "final_model = Model(inputs = [protein_1, protein_2], outputs = x)\n",
        "final_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4l6MrsoDjs9D"
      },
      "outputs": [],
      "source": [
        "final_model.compile(optimizer='adam',loss=loss_function, metrics = metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFk0p-nfF8Ev"
      },
      "outputs": [],
      "source": [
        "final_model.load_weights('/content/drive/MyDrive/saved_models/2024_01_07_17_04/final_weights_LSTM5.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJkdhmZBTlhi"
      },
      "outputs": [],
      "source": [
        "\"\"\"visualizer(final_model, file_format='png', view=True)\n",
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(final_model, to_file='model.png', show_shapes=True, show_layer_names=True)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiQ6AtP4bVGe"
      },
      "source": [
        "#Training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfuKDOOcZkbp"
      },
      "outputs": [],
      "source": [
        "final_model.fit(x_train, y_train, validation_data = (x_val, y_val), epochs = 1, callbacks = callbacks,batch_size=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Rpz5hLkGNP8b",
        "outputId": "8af0f302-38cb-4edf-eca4-9c86caa4cdb8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nlog_path = os.path.join(drive_path, '/logs/fit')\\n!mkdir -p $log_path\""
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "timestamp = datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\n",
        "drive_path = os.path.join('/content/drive/MyDrive/saved_models', timestamp)\n",
        "!mkdir -p $drive_path\n",
        "\"\"\"\n",
        "log_path = os.path.join(drive_path, '/logs/fit')\n",
        "!mkdir -p $log_path\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXeQdiuSLPTz"
      },
      "outputs": [],
      "source": [
        "final_model.save_weights(os.path.join(drive_path, f'final_weights_LSTM5.h5'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxQvjYx6b_Hu"
      },
      "outputs": [],
      "source": [
        "final_model.save(os.path.join(drive_path, f'final_model_LSTM5.h5'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJgDL_z2nOPh"
      },
      "source": [
        "#Load model & weights:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ppt7fq4evpZA"
      },
      "outputs": [],
      "source": [
        "loaded_model = tf.keras.models.load_model('/content/drive/MyDrive/saved_models/2024_01_07_17_04/final_model_LSTM5.h5')\n",
        "loaded_model.load_weights('/content/drive/MyDrive/saved_models/2024_01_07_17_04/final_weights_LSTM5.h5')\n",
        "#loaded_model.compile(optimizer='adam',loss=loss_function, metrics = metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zfAH4Hjv0Xn"
      },
      "outputs": [],
      "source": [
        "loaded_model.fit(x_train, y_train, validation_data = (x_val, y_val), epochs = 1, callbacks = callbacks,batch_size=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Fe9AV7hI7Mf"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "timestamp = datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\n",
        "drive_path = os.path.join('/content/drive/MyDrive/saved_models', timestamp)\n",
        "!mkdir -p $drive_path\n",
        "\n",
        "new_model.save_weights(os.path.join(drive_path, f'final_weights_LSTM10.h5'))\n",
        "new_model.save(drive_path,'final_model_LSTM10.h5')\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDMNxbDWHfKf"
      },
      "source": [
        "#LSTM Bidirectional:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7PSbaamkrlS"
      },
      "outputs": [],
      "source": [
        "#inputs\n",
        "protein_1 = tf.keras.layers.Input(shape=(fixed_length,), name='protein1')\n",
        "protein_2 = tf.keras.layers.Input(shape=(fixed_length,), name='protein2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2K-NzdXHrry"
      },
      "outputs": [],
      "source": [
        "embedding = tf.keras.layers.Embedding(input_dim = len(word_token) + 1, output_dim = 512, mask_zero = 1,  input_length=fixed_length)\n",
        "embedding_1 = embedding(protein_1)\n",
        "embedding_2 = embedding(protein_2)\n",
        "model_0 = Model(inputs = [protein_1, protein_2], outputs = [embedding_1,embedding_2])\n",
        "\n",
        "model_1 = Sequential()\n",
        "model_1.add(BatchNormalization(input_shape = (fixed_length,512)))\n",
        "model_1.add(Bidirectional(LSTM(name = 'LSTM_Layer',units = 64, activation='tanh', recurrent_activation='sigmoid')))\n",
        "model_1.add(Dense( 64, activation='elu'))\n",
        "model_1.add(BatchNormalization())\n",
        "model_1.add(Dropout(0.6))\n",
        "\n",
        "feature_array_128 = concatenate([model_1(model_0.outputs[0]), model_1(model_0.outputs[1])])\n",
        "x = Dense(512, activation='elu')(feature_array_128)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(1, activation='sigmoid')(x)\n",
        "final_model = Model(inputs = [protein_1, protein_2], outputs = x)\n",
        "final_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjQ-yzduOULt"
      },
      "outputs": [],
      "source": [
        "final_model.compile(optimizer='adam',loss=loss_function, metrics = metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pntQ1zw3OULu"
      },
      "outputs": [],
      "source": [
        "final_model.load_weights('/content/drive/MyDrive/saved_models/2024_01_10_LSTMB_Fin/final_weights_LSTMB.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYNce77YOchY"
      },
      "outputs": [],
      "source": [
        "#final_model.fit(x_train, y_train, validation_data = (x_val, y_val), epochs = 1, callbacks = callbacks,batch_size=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKL5RMdauAyP"
      },
      "outputs": [],
      "source": [
        "#%tensorboard --logdir logs/fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yw9wyLI4N3Pb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "c268ea64-8636-4e57-ef60-eefb736bc134"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'timestamp = datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\\ndrive_path = os.path.join(\\'/content/drive/MyDrive/saved_models\\', timestamp)\\n!mkdir -p $drive_path'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "\"\"\"timestamp = datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\n",
        "drive_path = os.path.join('/content/drive/MyDrive/saved_models', timestamp)\n",
        "!mkdir -p $drive_path\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdPBeBG3N3Pc"
      },
      "outputs": [],
      "source": [
        "#final_model.save_weights(os.path.join(drive_path, f'final_weights_LSTMB.h5'))\n",
        "final_model.save(os.path.join('/content/drive/MyDrive/saved_models/2024_01_10_LSTMB_Fin', f'final_model_LSTMB.h5'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svCLQDXfjbqJ"
      },
      "source": [
        "#Rate model performance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gozuyll94FPQ"
      },
      "outputs": [],
      "source": [
        "#Find the best threshold based on best mcc score on val data\n",
        "best_threshold,best_MCC = find_best_threshold(final_model, x_val, y_val)\n",
        "print(f'Best Matthews Correlation Coefficient: {best_MCC} at Threshold: {best_threshold}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ah95oxhyCP_6"
      },
      "outputs": [],
      "source": [
        "def evaluate_with_threshold(model, x_test, y_test, threshold):\n",
        "    y_pred = model.predict(x_test)\n",
        "    sens,spec,mcc,acc,prec, rec, f1,auc = calculate_metrics(y_test, y_pred, threshold)\n",
        "    print(f'For Threshold:{threshold}:\\nMCC = {mcc}\\nsensitivity = {sens}\\nspecificity = {spec}\\naccuracy = {acc}\\nprecision = {prec}\\nrecall = {rec}\\nf1-score = {f1}\\nauc = {auc}')\n",
        "\n",
        "# Evaluate the model with the best threshold\n",
        "evaluate_with_threshold(final_model, x_test, y_test, best_threshold)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "h1iaJoIHNS1N"
      },
      "outputs": [],
      "source": [
        "predictions = final_model.predict(x = x_test, callbacks = None )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JD1bQ9onjbqL"
      },
      "outputs": [],
      "source": [
        "rate_model(y_test, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mOS1fSOmPqjw"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "# Load the evaluation results\n",
        "evaluation_results_path = os.path.join(drive_path, 'evaluation_results.json')\n",
        "with open(evaluation_results_path, 'r') as file:\n",
        "    evaluation_results = json.load(file)\n",
        "\"\"\"\n",
        "y_true = output_test\n",
        "y_pred = predictions\n",
        "\n",
        "# Compute ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
        "\n",
        "# Compute area under the curve (AUC)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {roc_auc:.2f}')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5y9-7pX6fZCn"
      },
      "source": [
        "#Tester:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-udTfWn0S7P9"
      },
      "outputs": [],
      "source": [
        "#############"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgA0TNlNZ9tE"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(final_model, 'saved_model.joblib', protocol=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hb9VSqJyVaU1"
      },
      "outputs": [],
      "source": [
        "import cloudpickle\n",
        "\n",
        "with open('saved_model.pkl', 'wb') as file:\n",
        "    cloudpickle.dump(final_model, file)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "A_gX6z2sjn5X",
        "gZ3-ZINmAL-5",
        "1VyEmfkyBSdy",
        "NQ30ic_CAL-7",
        "x9uOuuygAL-9",
        "p6EoSSPRAL-8",
        "X1O6kARfaQlE",
        "RiQ6AtP4bVGe",
        "UJgDL_z2nOPh",
        "svCLQDXfjbqJ",
        "5y9-7pX6fZCn"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}