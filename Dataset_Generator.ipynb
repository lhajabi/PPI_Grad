{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lhajabi/PPI_Grad/blob/main/Dataset_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generator"
      ],
      "metadata": {
        "id": "QCTtTS2Wccnl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "WoV_33ZmXhmF",
        "outputId": "6162126b-f2ce-4f42-c670-f34250b6bc88"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"ONLY RUNS IF GPU AVAILABLE\\nimport tensorflow as tf\\ndevice_name = tf.test.gpu_device_name()\\nif device_name != '/device:GPU:0':\\n  raise SystemError('GPU device not found')\\nprint('Found GPU at: {}'.format(device_name))\\n\\ndef gpu():\\n  with tf.device('/device:GPU:0'):\\n    random_image_gpu = tf.random.normal((100, 100, 100, 3))\\n    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\\n    return tf.math.reduce_sum(net_gpu)\\n\\ngpu()\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "\"\"\"ONLY RUNS IF GPU AVAILABLE\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "def gpu():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "    return tf.math.reduce_sum(net_gpu)\n",
        "\n",
        "gpu()\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzigedgzgWuI",
        "outputId": "61ff6889-3fc3-4e5e-c45b-024c17e81a6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/MyDrive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive\n",
        "\"\"\"drive.flush_and_unmount()\n",
        "!mkdir /content/MyDrive\"\"\"\n",
        "drive.mount('/content/MyDrive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piczB9KsXC8w"
      },
      "outputs": [],
      "source": [
        "\"\"\"---------------------------------------------------------------------------------------------------------------------\n",
        "Specify Dataset parameters for the required dataset:\n",
        "CD_POS: True or False\n",
        "CD_NEG: True or False\n",
        "CD_Val: int = 40 or int = 60 (refers to sequences similarity \"strictness\" ex:60 less strict than 40)\n",
        "num_samples: int\n",
        "ratio: float 0 to 1 ratio of negative to posotive samples (ex: 0.9 => 90% neg and 10% pos)\n",
        "confidence: 'medium' = 0.4 conf or 'high' = 0.7 conf for the positive samples\n",
        "***last code block in Generator has the save dataset cmd make sure to recomment it so as not to overright existing files\n",
        "------------------------------------------------------------------------------------------------------------------------\"\"\"\n",
        "CD_POS = True\n",
        "CD_NEG = False\n",
        "CD__POS_Val = 40\n",
        "CD__NEG_Val = 40\n",
        "num_samples = 200000\n",
        "ratio = 0.5\n",
        "confidence = 'high'\n",
        "seed = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16smuIyP0oPN"
      },
      "source": [
        "POSITIVE PART:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VfzGCQLX_OP"
      },
      "outputs": [],
      "source": [
        "if CD_POS == False:\n",
        "  if confidence == 'medium':\n",
        "    positive_df = pd.read_csv('/content/MyDrive/MyDrive/Data/ONLY POSITIVE/ALL_POS(0.4).txt', delimiter=',')### 1,858,944 samples\n",
        "  else:\n",
        "    positive_df = pd.read_csv('/content/MyDrive/MyDrive/Data/ONLY POSITIVE/ALL_POS(0.7).txt', delimiter=',')### 473,860 samples\n",
        "elif CD__POS_Val !=60:\n",
        "  if confidence == 'medium':\n",
        "    positive_df = pd.read_csv('/content/MyDrive/MyDrive/Data/ONLY POSITIVE/ALL_POS_CD40(0.4).txt', delimiter=',')## 421,792 samples\n",
        "  else:\n",
        "    positive_df = pd.read_csv('/content/MyDrive/MyDrive/Data/ONLY POSITIVE/ALL_POS_CD40(0.7).txt', delimiter=',')### 122,242 samples\n",
        "else:\n",
        "  if confidence == 'medium':\n",
        "    positive_df = pd.read_csv('/content/MyDrive/MyDrive/Data/ONLY POSITIVE/ALL_POS_CD60(0.4).txt', delimiter=',')### 604,994 samples\n",
        "  else:\n",
        "    positive_df = pd.read_csv('/content/MyDrive/MyDrive/Data/ONLY POSITIVE/ALL_POS_CD60(0.7).txt', delimiter=',')### 162,506 samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaANLQLH0r4a"
      },
      "source": [
        "NEGATIVE PART:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0Glu-BP0yOh"
      },
      "outputs": [],
      "source": [
        "if CD_NEG == False:\n",
        "  negative_df = pd.read_csv('/content/MyDrive/MyDrive/Data/ONLY NEGATIVE/ALL_NEG.txt', delimiter=',')### 196,569 samples\n",
        "elif CD__NEG_Val !=60:\n",
        "  negative_df = pd.read_csv('/content/MyDrive/MyDrive/Data/ONLY NEGATIVE/ALL_NEG_CD40.txt', delimiter=',')### 8,176 samples\n",
        "else:\n",
        "  negative_df = pd.read_csv('/content/MyDrive/MyDrive/Data/ONLY NEGATIVE/ALL_NEG_CD60.txt', delimiter=',')### 14,259 samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9w7ewQ_7Xsa"
      },
      "source": [
        "COMBINE:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJAA7e-DiMF-"
      },
      "outputs": [],
      "source": [
        "def _scale_down_dataframe(input_df, combined_score, total_samples=10000, random_seed=41):\n",
        "    if combined_score == 1:\n",
        "        group_ones = input_df[input_df['combined_score'] == 1]\n",
        "        sample_ones = group_ones.sample(n=min(total_samples, len(group_ones)), random_state=random_seed)\n",
        "        return sample_ones\n",
        "    else:\n",
        "        group_zeros = input_df[input_df['combined_score'] == 0]\n",
        "        sample_zeros = group_zeros.sample(n=min(total_samples, len(group_zeros)), random_state=random_seed)\n",
        "        return sample_zeros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UaCIUnwOTTAJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52ed70ee-012d-4fb2-c5f0-4806c298ef4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1    100000\n",
            "0    100000\n",
            "Name: combined_score, dtype: int64\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 200000 entries, 0 to 199999\n",
            "Data columns (total 3 columns):\n",
            " #   Column          Non-Null Count   Dtype \n",
            "---  ------          --------------   ----- \n",
            " 0   protein1        200000 non-null  object\n",
            " 1   protein2        200000 non-null  object\n",
            " 2   combined_score  200000 non-null  int64 \n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 4.6+ MB\n"
          ]
        }
      ],
      "source": [
        "pos_samples = int(num_samples - (num_samples * ratio))\n",
        "neg_samples = int(num_samples * ratio)\n",
        "\n",
        "pos_samples = min(pos_samples, len(positive_df))\n",
        "neg_samples = min(neg_samples, len(negative_df))\n",
        "\n",
        "if pos_samples + neg_samples != num_samples:\n",
        "  if min(pos_samples,neg_samples) ==  neg_samples:\n",
        "    new_num_samples = neg_samples / ratio\n",
        "    pos_samples = int(new_num_samples - (new_num_samples * ratio))\n",
        "  else:\n",
        "    new_num_samples = pos_samples / ratio\n",
        "    neg_samples = int(num_samples * ratio)\n",
        "\n",
        "positive_df_sample = _scale_down_dataframe(input_df = positive_df, combined_score= 1, total_samples= pos_samples, random_seed=seed)\n",
        "negative_df_sample = _scale_down_dataframe(input_df = negative_df, combined_score= 0, total_samples= neg_samples, random_seed=seed)\n",
        "\n",
        "final_df = pd.concat([positive_df_sample, negative_df_sample])\n",
        "\n",
        "final_df = final_df.reset_index(drop=True)\n",
        "print(final_df['combined_score'].value_counts())\n",
        "final_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e730rHpDaRIM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "drive_path = '/content/MyDrive/MyDrive/Data/GENERATED DATASETS'\n",
        "\n",
        "if not os.path.exists(drive_path):\n",
        "    os.makedirs(drive_path)\n",
        "\n",
        "os.chdir(drive_path)\n",
        "#final_df.to_csv('Generated200k_(POS40-0.7)_50:50.txt', index=False) #save your df to txt file\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tester:"
      ],
      "metadata": {
        "id": "T0mGnct3Eu9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fasta_file_path = '/content/drive/MyDrive/Data/9606.protein.sequences.v12.0.fa'\n"
      ],
      "metadata": {
        "id": "EULXLvcdEwlv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}